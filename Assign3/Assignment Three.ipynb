{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Learning Course (980)\n",
    "## Assignment Three \n",
    "\n",
    "__Assignment Goals:__\n",
    "\n",
    "- Implementing RNN based language models.\n",
    "- Implementing and applying a Recurrent Neural Network on text classification problem using TensorFlow.\n",
    "- Implementing __many to one__ and __many to many__ RNN sequence processing.\n",
    "\n",
    "In this assignment, you will implement RNN-based language models and compare extracted word representation from different models. You will also compare two different training methods for sequential data: Truncated Backpropagation Through Time __(TBTT)__ and Backpropagation Through Time __(BTT)__. \n",
    "Also, you will be asked to apply Vanilla RNN to capture word representations and solve a text classification problem. \n",
    "\n",
    "\n",
    "__DataSets__: You will use two datasets, an English Literature for language model task (part 1 to 4) and 20Newsgroups for text classification (part 5). \n",
    "\n",
    "\n",
    "1. (30 points) Implement the RNN based language model described by Mikolov et al.[1], also called __Elman network__ and train a language model on the English Literature dataset. This network contains input, hidden and output layer and is trained by standard backpropagation (TBTT with τ = 1) using the cross-entropy loss. \n",
    "   - The input represents the current word while using 1-of-N coding (thus its size is equal to the size of the vocabulary) and vector s(t − 1) that represents output values in the hidden layer from the previous time step. \n",
    "   - The hidden layer is a fully connected sigmoid layer with size 500. \n",
    "   - Softmax Output Layer to capture a valid probability distribution.\n",
    "   - The model is trained with truncated backpropagation through time (TBTT) with τ = 1: the weights of the network are updated based on the error vector computed only for the current time step.\n",
    "   \n",
    "   Download the English Literature dataset and train the language model as described, report the model cross-entropy loss on the train set. Use nltk.word_tokenize to tokenize the documents. \n",
    "For initialization, s(0) can be set to a vector of small values. To improve performance, you can merge all words that occur less often than a threshold (here 3) into a special rare token (\\__unk__). Note that we are not interested in the *dynamic model* mentioned in the original paper. \n",
    "To make the implementation simpler you can use Keras to define neural net layers, including Keras.Embedding. (Keras.Embedding will create an additional mapping layer compared to the Elman architecture.) \n",
    "\n",
    "2. (20 points) TBTT has less computational cost and memory needs in comparison with *backpropagation through time algorithm (BTT)*. These benefits come at the cost of losing long term dependencies [2]. Now let's try to investigate computational costs and performance of learning our language model with BTT. For training the Elman-type RNN with BTT, one option is to perform mini-batch gradient descent with exactly one sentence per mini-batch. (The input  size will be [1, Sentence Length]). \n",
    "\n",
    "    1. Split the document into sentences (you can use nltk.tokenize.sent_tokenize).\n",
    "    2. For each sentence, perform one pass that computes the mean/sum loss for this sentence; then perform a gradient update for the whole sentence. (So the mini-batch size varies for the sentences with different lengths). You can truncate long sentences to fit the data in memory. \n",
    "    3. Report the model cross-entropy loss.\n",
    "\n",
    "3. (15 points) It does not seem that simple recurrent neural networks can capture truly exploit context information with long dependencies, because of the problem that gradients vanish and exploding. To solve this problem, gating mechanisms for recurrent neural networks were introduced. Try to learn your last model (Elman + BTT) with the SimpleRnn unit replaced with a Gated Recurrent Unit (GRU). Report the model cross-entropy loss. Compare your results in terms of cross-entropy loss with two other approach(part 1 and 2). Use each model to generate 10 synthetic sentences of 15 words each. Discuss the quality of the sentences generated - do they look like proper English? Do they match the training set?\n",
    "    Text generation from a given language model can be done using the following iterative process:\n",
    "   1. Set sequence = \\[first_word\\], chosen randomly.\n",
    "   2. Select a new word based on the sequence so far, add this word to the sequence, and repeat. At each iteration, select the word with maximum probability given the sequence so far. The trained language model outputs this probability. \n",
    "\n",
    "4. (15 points) The text describes how to extract a word representation from a trained RNN (Chapter 4). How we can evaluate the extracted word representation for your trained RNN? Compare the words representation extracted from each of the approaches using one of the existing methods.\n",
    "\n",
    "5. (20 points) We are aiming to learn an RNN model that predicts document categories given its content (text classification). For this task, we will use the 20Newsgroupst dataset. The 20Newsgroupst contains messages from twenty newsgroups.  We selected four major categories (comp, politics, rec, and religion) comprising around 13k documents altogether. Your model should learn word representations to support the classification task. For solving this problem modify the __Elman network__ architecture such that the last layer is a softmax layer with just 4 output neurons (one for each category). \n",
    "\n",
    "    1. Download the 20Newsgroups dataset, and use the implemented code from the notebook to read in the dataset.\n",
    "    2. Split the data into a training set (90 percent) and validation set (10 percent). Train the model on  20Newsgroups.\n",
    "    3. Report your accuracy results on the validation set.\n",
    "\n",
    "__NOTE__: Please use Jupyter Notebook. The notebook should include the final code, results and your answers. You should submit your Notebook in (.pdf or .html) and .ipynb format. (penalty 10 points) \n",
    "\n",
    "__Instructions__:\n",
    "\n",
    "The university policy on academic dishonesty and plagiarism (cheating) will be taken very seriously in this course. Everything submitted should be your own writing or coding. You must not let other students copy your work. Spelling and grammar count.\n",
    "\n",
    "Your assignments will be marked based on correctness, originality (the implementations and ideas are from yourself), clarification and test performance.\n",
    "\n",
    "\n",
    "[1] Tom´ as Mikolov, Martin Kara ˇ fiat, Luk´ ´ as Burget, Jan ˇ Cernock´ ˇ y,Sanjeev Khudanpur: Recurrent neural network based language model, In: Proc. INTERSPEECH 2010\n",
    "\n",
    "[2] Tallec, Corentin, and Yann Ollivier. \"Unbiasing truncated backpropagation through time.\" arXiv preprint arXiv:1705.08209 (2017).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/lpan/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import string\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, SimpleRNN, GRU, Dense, Dropout\n",
    "from keras.callbacks import CSVLogger, ModelCheckpoint, TensorBoard\n",
    "from keras import optimizers\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total vocabulary size:  4650\n",
      "y shape:  200600\n",
      "X shape:  (200600, 1)\n",
      "Y shape:  (200600, 4650)\n"
     ]
    }
   ],
   "source": [
    "# Part1\n",
    "# Import file\n",
    "def load_doc(filename):\n",
    "    file = open(filename, 'r')\n",
    "    raw_text = file.read()\n",
    "    file.close()\n",
    "    return raw_text\n",
    "\n",
    "raw_text = load_doc('English Literature.txt')\n",
    "tokens = nltk.word_tokenize(raw_text)\n",
    "\n",
    "# Data cleaning\n",
    "translator = str.maketrans('', '', string.punctuation)\n",
    "tokens_cleaned = [s.translate(translator).lower() for s in tokens if s.isalpha()]\n",
    "# print('before cleaning: ', tokens[:5])\n",
    "tokens = tokens_cleaned\n",
    "# print('before cleaning: ', tokens[:5])\n",
    "\n",
    "# Merge all words that occur less often than a threshold into a special rare token (_unk_), and create word dictionary\n",
    "threshold = 3\n",
    "word_dict = {'pad': 0, '_unk_': 1}  # 'pad' for use in part 2\n",
    "idx2word = ['pad','_unk_']\n",
    "counter = Counter(tokens)\n",
    "for word, count in counter.items():\n",
    "    if count >= threshold:\n",
    "        idx2word.append(word)\n",
    "        word_dict[word] = len(word_dict)\n",
    "vocab_size = len(word_dict)\n",
    "print('total vocabulary size: ', vocab_size)\n",
    "\n",
    "# Map to training data X and y\n",
    "X = []\n",
    "y = []\n",
    "max_length = 1\n",
    "for i in range(len(tokens) - max_length):\n",
    "    sentence = tokens[i:i+max_length]\n",
    "    gt_word = tokens[i+max_length]\n",
    "    X.append([word_dict.get(word,1) for word in sentence])\n",
    "    y.append(word_dict.get(gt_word,1))\n",
    "X = np.array(X)\n",
    "print('y shape: ', len(y))\n",
    "# One hot encoding\n",
    "Y = to_categorical(y, vocab_size)\n",
    "print('X shape: ', X.shape)\n",
    "print('Y shape: ', Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_10 (Embedding)     (None, 1, 50)             232500    \n",
      "_________________________________________________________________\n",
      "simple_rnn_7 (SimpleRNN)     (None, 500)               275500    \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 4650)              2329650   \n",
      "=================================================================\n",
      "Total params: 2,837,650\n",
      "Trainable params: 2,837,650\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Build model\n",
    "max_length = 1\n",
    "model1 = Sequential()\n",
    "model1.add(Embedding(vocab_size, 50, input_length=max_length))\n",
    "model1.add(SimpleRNN(500, activation='sigmoid'))\n",
    "model1.add(Dense(vocab_size, activation='softmax'))\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lpan/.local/lib/python3.5/site-packages/tensorflow_core/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "200600/200600 [==============================] - 51s 252us/step - loss: 6.2367 - accuracy: 0.0639\n",
      "Epoch 2/30\n",
      "200600/200600 [==============================] - 50s 247us/step - loss: 5.7112 - accuracy: 0.0920\n",
      "Epoch 3/30\n",
      "200600/200600 [==============================] - 50s 248us/step - loss: 5.5182 - accuracy: 0.1005\n",
      "Epoch 4/30\n",
      "200600/200600 [==============================] - 50s 248us/step - loss: 5.3746 - accuracy: 0.1055\n",
      "Epoch 5/30\n",
      "200600/200600 [==============================] - 50s 248us/step - loss: 5.2489 - accuracy: 0.1071\n",
      "Epoch 6/30\n",
      "200600/200600 [==============================] - 50s 248us/step - loss: 5.1313 - accuracy: 0.1077\n",
      "Epoch 7/30\n",
      "200600/200600 [==============================] - 50s 248us/step - loss: 5.0217 - accuracy: 0.1072\n",
      "Epoch 8/30\n",
      "200600/200600 [==============================] - 50s 251us/step - loss: 4.9257 - accuracy: 0.1069\n",
      "Epoch 9/30\n",
      "200600/200600 [==============================] - 50s 252us/step - loss: 4.8501 - accuracy: 0.1057\n",
      "Epoch 10/30\n",
      "200600/200600 [==============================] - 50s 251us/step - loss: 4.7903 - accuracy: 0.1060\n",
      "\n",
      "Epoch 00010: loss improved from inf to 4.79031, saving model to checkpoints_part1/epoch-10-accu-0.1060-loss-4.7903.hdf5\n",
      "Epoch 11/30\n",
      "200600/200600 [==============================] - 51s 255us/step - loss: 4.7450 - accuracy: 0.1061\n",
      "Epoch 12/30\n",
      "200600/200600 [==============================] - 50s 252us/step - loss: 4.7093 - accuracy: 0.1052\n",
      "Epoch 13/30\n",
      "200600/200600 [==============================] - 51s 252us/step - loss: 4.6796 - accuracy: 0.1050\n",
      "Epoch 14/30\n",
      "200600/200600 [==============================] - 51s 252us/step - loss: 4.6565 - accuracy: 0.1048\n",
      "Epoch 15/30\n",
      "200600/200600 [==============================] - 51s 252us/step - loss: 4.6360 - accuracy: 0.1045\n",
      "Epoch 16/30\n",
      "200600/200600 [==============================] - 51s 252us/step - loss: 4.6197 - accuracy: 0.1043\n",
      "Epoch 17/30\n",
      "200600/200600 [==============================] - 50s 251us/step - loss: 4.6057 - accuracy: 0.1049\n",
      "Epoch 18/30\n",
      "200600/200600 [==============================] - 50s 249us/step - loss: 4.5922 - accuracy: 0.1049\n",
      "Epoch 19/30\n",
      "200600/200600 [==============================] - 50s 249us/step - loss: 4.5815 - accuracy: 0.1049\n",
      "Epoch 20/30\n",
      "200600/200600 [==============================] - 51s 252us/step - loss: 4.5719 - accuracy: 0.1048\n",
      "\n",
      "Epoch 00020: loss improved from 4.79031 to 4.57190, saving model to checkpoints_part1/epoch-20-accu-0.1048-loss-4.5719.hdf5\n",
      "Epoch 21/30\n",
      "200600/200600 [==============================] - 50s 252us/step - loss: 4.5627 - accuracy: 0.1047\n",
      "Epoch 22/30\n",
      "200600/200600 [==============================] - 51s 252us/step - loss: 4.5552 - accuracy: 0.1051\n",
      "Epoch 23/30\n",
      "200600/200600 [==============================] - 50s 251us/step - loss: 4.5474 - accuracy: 0.1044\n",
      "Epoch 24/30\n",
      "200600/200600 [==============================] - 50s 251us/step - loss: 4.5407 - accuracy: 0.1051\n",
      "Epoch 25/30\n",
      "200600/200600 [==============================] - 51s 252us/step - loss: 4.5337 - accuracy: 0.1053\n",
      "Epoch 26/30\n",
      "200600/200600 [==============================] - 50s 251us/step - loss: 4.5288 - accuracy: 0.1047\n",
      "Epoch 27/30\n",
      "200600/200600 [==============================] - 51s 253us/step - loss: 4.5236 - accuracy: 0.1058\n",
      "Epoch 28/30\n",
      "200600/200600 [==============================] - 51s 252us/step - loss: 4.5189 - accuracy: 0.1052\n",
      "Epoch 29/30\n",
      "200600/200600 [==============================] - 51s 253us/step - loss: 4.5145 - accuracy: 0.1052\n",
      "Epoch 30/30\n",
      "200600/200600 [==============================] - 51s 253us/step - loss: 4.5102 - accuracy: 0.1055\n",
      "\n",
      "Epoch 00030: loss improved from 4.57190 to 4.51024, saving model to checkpoints_part1/epoch-30-accu-0.1055-loss-4.5102.hdf5\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "part1_root_folder = 'checkpoints_part1'\n",
    "checkpointer1 = ModelCheckpoint(\n",
    "        filepath=part1_root_folder+'/epoch-{epoch:02d}-accu-{accuracy:.4f}-loss-{loss:.4f}.hdf5',\n",
    "        monitor='loss',\n",
    "        verbose=1,\n",
    "        save_best_only=True, mode='auto', period=10)\n",
    "logfile1 = CSVLogger(part1_root_folder+'/train.log', append=False, separator=',')\n",
    "adam = optimizers.Adam(lr=0.005)\n",
    "model1.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
    "history1 = model1.fit(X,Y,\n",
    "        batch_size=128,\n",
    "        epochs=30,\n",
    "        verbose=1,\n",
    "        callbacks=[checkpointer1, logfile1],\n",
    "        workers=4)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Part1: I did some cleaning on the raw data, such as removing punctuation and converting to lowercase letters. I trained 30 epochs. The SimpleRNN + TBTT model's cross-entropy loss on the train set is 4.5102.     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part2\n",
    "raw_text = raw_text.replace('\\n', ' ').replace('\\r', '') # replace new lines with spaces\n",
    "sentences = nltk.sent_tokenize(raw_text)\n",
    "max_length = 30 # truncate long sentence\n",
    "sequences = list()\n",
    "for sentence in sentences:\n",
    "    tokens = nltk.word_tokenize(sentence)\n",
    "    translator = str.maketrans('', '', string.punctuation)\n",
    "    tokens_cleaned = [s.translate(translator).lower() for s in tokens if s.isalpha()]\n",
    "    tokens = tokens_cleaned\n",
    "    encoded = [word_dict.get(word, 1) for word in tokens]\n",
    "    for i in range(1, min(len(encoded), max_length)):\n",
    "        sequence = encoded[:i+1]\n",
    "        sequences.append(sequence)\n",
    "sequences =  np.array(pad_sequences(sequences, maxlen=max_length, padding='pre'))\n",
    "# print(sequences.shape)\n",
    "X = sequences[:,:-1] # length - 1\n",
    "y = sequences[:,-1]\n",
    "Y = to_categorical(y, num_classes=vocab_size)\n",
    "# print(X.shape)\n",
    "# print(Y.shape)\n",
    "\n",
    "# def seq2sentence(seq):\n",
    "#     sentence = ''\n",
    "#     for i in range(len(seq)):\n",
    "#         sentence += idx2word[seq[i]] + ' '\n",
    "#     print(sentence.strip())\n",
    "# seq2sentence([3645, 4272, 490, 4263, 3150, 1927, 3520, 2444, 5209, 2970, 4781, 3168, 1797]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_8 (Embedding)      (None, 29, 50)            232500    \n",
      "_________________________________________________________________\n",
      "simple_rnn_6 (SimpleRNN)     (None, 500)               275500    \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 4650)              2329650   \n",
      "=================================================================\n",
      "Total params: 2,837,650\n",
      "Trainable params: 2,837,650\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Build model\n",
    "model2 = Sequential()\n",
    "model2.add(Embedding(vocab_size, 50, input_length=max_length-1, mask_zero=True))\n",
    "model2.add(SimpleRNN(500, activation='sigmoid'))\n",
    "model2.add(Dense(vocab_size, activation='softmax'))\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lpan/.local/lib/python3.5/site-packages/tensorflow_core/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "158071/158071 [==============================] - 92s 583us/step - loss: 6.0107 - accuracy: 0.0743\n",
      "Epoch 2/60\n",
      "158071/158071 [==============================] - 91s 574us/step - loss: 5.4801 - accuracy: 0.1091\n",
      "Epoch 3/60\n",
      "158071/158071 [==============================] - 91s 573us/step - loss: 5.2215 - accuracy: 0.1214\n",
      "Epoch 4/60\n",
      "158071/158071 [==============================] - 92s 581us/step - loss: 4.9961 - accuracy: 0.1313\n",
      "Epoch 5/60\n",
      "158071/158071 [==============================] - 92s 581us/step - loss: 4.7763 - accuracy: 0.1397\n",
      "Epoch 6/60\n",
      "158071/158071 [==============================] - 90s 568us/step - loss: 4.5445 - accuracy: 0.1491\n",
      "Epoch 7/60\n",
      "158071/158071 [==============================] - 92s 579us/step - loss: 4.3092 - accuracy: 0.1610\n",
      "Epoch 8/60\n",
      "158071/158071 [==============================] - 92s 579us/step - loss: 4.0766 - accuracy: 0.1779\n",
      "Epoch 9/60\n",
      "158071/158071 [==============================] - 92s 579us/step - loss: 3.8552 - accuracy: 0.2001\n",
      "Epoch 10/60\n",
      "158071/158071 [==============================] - 90s 570us/step - loss: 3.6486 - accuracy: 0.2245\n",
      "\n",
      "Epoch 00010: loss improved from inf to 3.64862, saving model to checkpoints_part2/epoch-10-accu-0.2245-loss-3.6486.hdf5\n",
      "Epoch 11/60\n",
      "158071/158071 [==============================] - 91s 578us/step - loss: 3.4552 - accuracy: 0.2495\n",
      "Epoch 12/60\n",
      "158071/158071 [==============================] - 92s 584us/step - loss: 3.2797 - accuracy: 0.2748\n",
      "Epoch 13/60\n",
      "158071/158071 [==============================] - 92s 585us/step - loss: 3.1170 - accuracy: 0.3010\n",
      "Epoch 14/60\n",
      "158071/158071 [==============================] - 92s 585us/step - loss: 2.9669 - accuracy: 0.3248\n",
      "Epoch 15/60\n",
      "158071/158071 [==============================] - 92s 584us/step - loss: 2.8329 - accuracy: 0.3482\n",
      "Epoch 16/60\n",
      "158071/158071 [==============================] - 92s 585us/step - loss: 2.7102 - accuracy: 0.3713\n",
      "Epoch 17/60\n",
      "158071/158071 [==============================] - 94s 592us/step - loss: 2.5970 - accuracy: 0.3911\n",
      "Epoch 18/60\n",
      "158071/158071 [==============================] - 93s 591us/step - loss: 2.4992 - accuracy: 0.4108\n",
      "Epoch 19/60\n",
      "158071/158071 [==============================] - 93s 591us/step - loss: 2.4078 - accuracy: 0.4276\n",
      "Epoch 20/60\n",
      "158071/158071 [==============================] - 93s 591us/step - loss: 2.3269 - accuracy: 0.4436\n",
      "\n",
      "Epoch 00020: loss improved from 3.64862 to 2.32693, saving model to checkpoints_part2/epoch-20-accu-0.4436-loss-2.3269.hdf5\n",
      "Epoch 21/60\n",
      "158071/158071 [==============================] - 93s 588us/step - loss: 2.2534 - accuracy: 0.4558\n",
      "Epoch 22/60\n",
      "158071/158071 [==============================] - 93s 591us/step - loss: 2.1889 - accuracy: 0.4699\n",
      "Epoch 23/60\n",
      "158071/158071 [==============================] - 94s 592us/step - loss: 2.1261 - accuracy: 0.4822\n",
      "Epoch 24/60\n",
      "158071/158071 [==============================] - 94s 592us/step - loss: 2.0714 - accuracy: 0.4925\n",
      "Epoch 25/60\n",
      "158071/158071 [==============================] - 93s 591us/step - loss: 2.0268 - accuracy: 0.5018\n",
      "Epoch 26/60\n",
      "158071/158071 [==============================] - 94s 595us/step - loss: 1.9789 - accuracy: 0.5103\n",
      "Epoch 27/60\n",
      "158071/158071 [==============================] - 93s 590us/step - loss: 1.9369 - accuracy: 0.5206\n",
      "Epoch 28/60\n",
      "158071/158071 [==============================] - 93s 591us/step - loss: 1.9008 - accuracy: 0.5269\n",
      "Epoch 29/60\n",
      "158071/158071 [==============================] - 94s 592us/step - loss: 1.8656 - accuracy: 0.5336\n",
      "Epoch 30/60\n",
      "158071/158071 [==============================] - 94s 594us/step - loss: 1.8399 - accuracy: 0.5383\n",
      "\n",
      "Epoch 00030: loss improved from 2.32693 to 1.83989, saving model to checkpoints_part2/epoch-30-accu-0.5383-loss-1.8399.hdf5\n",
      "Epoch 31/60\n",
      "158071/158071 [==============================] - 92s 585us/step - loss: 1.8152 - accuracy: 0.5437\n",
      "Epoch 32/60\n",
      "158071/158071 [==============================] - 92s 585us/step - loss: 1.7856 - accuracy: 0.5484\n",
      "Epoch 33/60\n",
      "158071/158071 [==============================] - 92s 585us/step - loss: 1.7643 - accuracy: 0.5532\n",
      "Epoch 34/60\n",
      "158071/158071 [==============================] - 93s 586us/step - loss: 1.7353 - accuracy: 0.5598\n",
      "Epoch 35/60\n",
      "158071/158071 [==============================] - 93s 585us/step - loss: 1.7149 - accuracy: 0.5627\n",
      "Epoch 36/60\n",
      "158071/158071 [==============================] - 93s 586us/step - loss: 1.6987 - accuracy: 0.5659\n",
      "Epoch 37/60\n",
      "158071/158071 [==============================] - 94s 593us/step - loss: 1.6834 - accuracy: 0.5711\n",
      "Epoch 38/60\n",
      "158071/158071 [==============================] - 94s 592us/step - loss: 1.6675 - accuracy: 0.5721\n",
      "Epoch 39/60\n",
      "158071/158071 [==============================] - 94s 593us/step - loss: 1.6560 - accuracy: 0.5736\n",
      "Epoch 40/60\n",
      "158071/158071 [==============================] - 94s 592us/step - loss: 1.6416 - accuracy: 0.5767\n",
      "\n",
      "Epoch 00040: loss improved from 1.83989 to 1.64163, saving model to checkpoints_part2/epoch-40-accu-0.5767-loss-1.6416.hdf5\n",
      "Epoch 41/60\n",
      "158071/158071 [==============================] - 94s 592us/step - loss: 1.6272 - accuracy: 0.5799\n",
      "Epoch 42/60\n",
      "158071/158071 [==============================] - 94s 596us/step - loss: 1.6172 - accuracy: 0.5818\n",
      "Epoch 43/60\n",
      "158071/158071 [==============================] - 93s 588us/step - loss: 1.6086 - accuracy: 0.5830\n",
      "Epoch 44/60\n",
      "158071/158071 [==============================] - 93s 586us/step - loss: 1.5906 - accuracy: 0.5880\n",
      "Epoch 45/60\n",
      "158071/158071 [==============================] - 93s 586us/step - loss: 1.5809 - accuracy: 0.5887\n",
      "Epoch 46/60\n",
      "158071/158071 [==============================] - 93s 589us/step - loss: 1.5907 - accuracy: 0.5861\n",
      "Epoch 47/60\n",
      "158071/158071 [==============================] - 93s 587us/step - loss: 1.5774 - accuracy: 0.5900\n",
      "Epoch 48/60\n",
      "158071/158071 [==============================] - 94s 594us/step - loss: 1.5670 - accuracy: 0.5903\n",
      "Epoch 49/60\n",
      "158071/158071 [==============================] - 94s 593us/step - loss: 1.5566 - accuracy: 0.5946\n",
      "Epoch 50/60\n",
      "158071/158071 [==============================] - 94s 593us/step - loss: 1.5472 - accuracy: 0.5972\n",
      "\n",
      "Epoch 00050: loss improved from 1.64163 to 1.54721, saving model to checkpoints_part2/epoch-50-accu-0.5972-loss-1.5472.hdf5\n",
      "Epoch 51/60\n",
      "158071/158071 [==============================] - 94s 594us/step - loss: 1.5443 - accuracy: 0.5949\n",
      "Epoch 52/60\n",
      "158071/158071 [==============================] - 94s 592us/step - loss: 1.5465 - accuracy: 0.5946\n",
      "Epoch 53/60\n",
      "158071/158071 [==============================] - 93s 587us/step - loss: 1.5313 - accuracy: 0.5992\n",
      "Epoch 54/60\n",
      "158071/158071 [==============================] - 93s 586us/step - loss: 1.5324 - accuracy: 0.5977\n",
      "Epoch 55/60\n",
      "158071/158071 [==============================] - 93s 588us/step - loss: 1.5314 - accuracy: 0.5991\n",
      "Epoch 56/60\n",
      "158071/158071 [==============================] - 93s 587us/step - loss: 1.5223 - accuracy: 0.5996\n",
      "Epoch 57/60\n",
      "158071/158071 [==============================] - 94s 594us/step - loss: 1.5148 - accuracy: 0.6012\n",
      "Epoch 58/60\n",
      "158071/158071 [==============================] - 94s 594us/step - loss: 1.5249 - accuracy: 0.5988\n",
      "Epoch 59/60\n",
      "158071/158071 [==============================] - 94s 595us/step - loss: 1.5129 - accuracy: 0.6027\n",
      "Epoch 60/60\n",
      "158071/158071 [==============================] - 94s 594us/step - loss: 1.5059 - accuracy: 0.6039\n",
      "\n",
      "Epoch 00060: loss improved from 1.54721 to 1.50586, saving model to checkpoints_part2/epoch-60-accu-0.6039-loss-1.5059.hdf5\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "part2_root_folder = 'checkpoints_part2'\n",
    "checkpointer2 = ModelCheckpoint(\n",
    "        filepath=part2_root_folder+'/epoch-{epoch:02d}-accu-{accuracy:.4f}-loss-{loss:.4f}.hdf5',\n",
    "        monitor='loss',\n",
    "        verbose=1,\n",
    "        save_best_only=True, mode='auto', period=10)\n",
    "logfile2 = CSVLogger(part2_root_folder+'/train.log', append=False, separator=',')\n",
    "adam = optimizers.Adam(lr=0.005)\n",
    "model2.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
    "history2 = model2.fit(X,Y,\n",
    "        batch_size=128,\n",
    "        epochs=60,\n",
    "        verbose=1,\n",
    "        callbacks=[checkpointer2, logfile2],\n",
    "        workers=4)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Part2: On epoch 60, the SimpleRNN + BTT model's cross-entropy loss on the train set is 1.5059. I cleaned punctuation and converted to lowercase words as before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_9 (Embedding)      (None, 29, 50)            232500    \n",
      "_________________________________________________________________\n",
      "gru_3 (GRU)                  (None, 500)               826500    \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 4650)              2329650   \n",
      "=================================================================\n",
      "Total params: 3,388,650\n",
      "Trainable params: 3,388,650\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Part3\n",
    "# Build model\n",
    "model3 = Sequential()\n",
    "model3.add(Embedding(vocab_size, 50, input_length=max_length-1, mask_zero=True))\n",
    "model3.add(GRU(500, activation='sigmoid'))\n",
    "model3.add(Dense(vocab_size, activation='softmax'))\n",
    "model3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lpan/.local/lib/python3.5/site-packages/tensorflow_core/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "158071/158071 [==============================] - 226s 1ms/step - loss: 5.4757 - accuracy: 0.1147\n",
      "Epoch 2/60\n",
      "158071/158071 [==============================] - 224s 1ms/step - loss: 5.0390 - accuracy: 0.1289\n",
      "Epoch 3/60\n",
      "158071/158071 [==============================] - 225s 1ms/step - loss: 4.6191 - accuracy: 0.1440\n",
      "Epoch 4/60\n",
      "158071/158071 [==============================] - 225s 1ms/step - loss: 4.1180 - accuracy: 0.1681\n",
      "Epoch 5/60\n",
      "158071/158071 [==============================] - 224s 1ms/step - loss: 3.5954 - accuracy: 0.2231\n",
      "Epoch 6/60\n",
      "158071/158071 [==============================] - 225s 1ms/step - loss: 3.1414 - accuracy: 0.2926\n",
      "Epoch 7/60\n",
      "158071/158071 [==============================] - 225s 1ms/step - loss: 2.7760 - accuracy: 0.3574\n",
      "Epoch 8/60\n",
      "158071/158071 [==============================] - 225s 1ms/step - loss: 2.4807 - accuracy: 0.4134\n",
      "Epoch 9/60\n",
      "158071/158071 [==============================] - 224s 1ms/step - loss: 2.2467 - accuracy: 0.4592\n",
      "Epoch 10/60\n",
      "158071/158071 [==============================] - 226s 1ms/step - loss: 2.0490 - accuracy: 0.5016\n",
      "\n",
      "Epoch 00010: loss improved from inf to 2.04903, saving model to checkpoints_part3/epoch-10-accu-0.5016-loss-2.0490.hdf5\n",
      "Epoch 11/60\n",
      "158071/158071 [==============================] - 226s 1ms/step - loss: 1.8838 - accuracy: 0.5380\n",
      "Epoch 12/60\n",
      "158071/158071 [==============================] - 226s 1ms/step - loss: 1.7470 - accuracy: 0.5657\n",
      "Epoch 13/60\n",
      "158071/158071 [==============================] - 226s 1ms/step - loss: 1.6319 - accuracy: 0.5932\n",
      "Epoch 14/60\n",
      "158071/158071 [==============================] - 226s 1ms/step - loss: 1.5428 - accuracy: 0.6115\n",
      "Epoch 15/60\n",
      "158071/158071 [==============================] - 226s 1ms/step - loss: 1.4597 - accuracy: 0.6297\n",
      "Epoch 16/60\n",
      "158071/158071 [==============================] - 226s 1ms/step - loss: 1.3901 - accuracy: 0.6444\n",
      "Epoch 17/60\n",
      "158071/158071 [==============================] - 226s 1ms/step - loss: 1.3321 - accuracy: 0.6580\n",
      "Epoch 18/60\n",
      "158071/158071 [==============================] - 226s 1ms/step - loss: 1.2824 - accuracy: 0.6692\n",
      "Epoch 19/60\n",
      "158071/158071 [==============================] - 227s 1ms/step - loss: 1.2403 - accuracy: 0.6790\n",
      "Epoch 20/60\n",
      "158071/158071 [==============================] - 227s 1ms/step - loss: 1.2025 - accuracy: 0.6880\n",
      "\n",
      "Epoch 00020: loss improved from 2.04903 to 1.20246, saving model to checkpoints_part3/epoch-20-accu-0.6880-loss-1.2025.hdf5\n",
      "Epoch 21/60\n",
      "158071/158071 [==============================] - 227s 1ms/step - loss: 1.1707 - accuracy: 0.6952\n",
      "Epoch 22/60\n",
      "158071/158071 [==============================] - 227s 1ms/step - loss: 1.1494 - accuracy: 0.6983\n",
      "Epoch 23/60\n",
      "158071/158071 [==============================] - 227s 1ms/step - loss: 1.1277 - accuracy: 0.7026\n",
      "Epoch 24/60\n",
      "158071/158071 [==============================] - 227s 1ms/step - loss: 1.1066 - accuracy: 0.7081\n",
      "Epoch 25/60\n",
      "158071/158071 [==============================] - 227s 1ms/step - loss: 1.0844 - accuracy: 0.7131\n",
      "Epoch 26/60\n",
      "158071/158071 [==============================] - 227s 1ms/step - loss: 1.0831 - accuracy: 0.7133\n",
      "Epoch 27/60\n",
      "158071/158071 [==============================] - 227s 1ms/step - loss: 1.0702 - accuracy: 0.7145\n",
      "Epoch 28/60\n",
      "158071/158071 [==============================] - 227s 1ms/step - loss: 1.0493 - accuracy: 0.7195\n",
      "Epoch 29/60\n",
      "158071/158071 [==============================] - 228s 1ms/step - loss: 1.0441 - accuracy: 0.7213\n",
      "Epoch 30/60\n",
      "158071/158071 [==============================] - 226s 1ms/step - loss: 1.0413 - accuracy: 0.7216\n",
      "\n",
      "Epoch 00030: loss improved from 1.20246 to 1.04127, saving model to checkpoints_part3/epoch-30-accu-0.7216-loss-1.0413.hdf5\n",
      "Epoch 31/60\n",
      "158071/158071 [==============================] - 226s 1ms/step - loss: 1.0437 - accuracy: 0.7196\n",
      "Epoch 32/60\n",
      "158071/158071 [==============================] - 226s 1ms/step - loss: 1.0331 - accuracy: 0.7224\n",
      "Epoch 33/60\n",
      "158071/158071 [==============================] - 226s 1ms/step - loss: 1.0212 - accuracy: 0.7257\n",
      "Epoch 34/60\n",
      "158071/158071 [==============================] - 226s 1ms/step - loss: 1.0176 - accuracy: 0.7263\n",
      "Epoch 35/60\n",
      "158071/158071 [==============================] - 227s 1ms/step - loss: 1.0204 - accuracy: 0.7251\n",
      "Epoch 36/60\n",
      "158071/158071 [==============================] - 227s 1ms/step - loss: 1.0168 - accuracy: 0.7252\n",
      "Epoch 37/60\n",
      "158071/158071 [==============================] - 227s 1ms/step - loss: 1.0213 - accuracy: 0.7236\n",
      "Epoch 38/60\n",
      "158071/158071 [==============================] - 227s 1ms/step - loss: 1.0090 - accuracy: 0.7259\n",
      "Epoch 39/60\n",
      "158071/158071 [==============================] - 227s 1ms/step - loss: 1.0106 - accuracy: 0.7265\n",
      "Epoch 40/60\n",
      "158071/158071 [==============================] - 227s 1ms/step - loss: 1.0106 - accuracy: 0.7249\n",
      "\n",
      "Epoch 00040: loss improved from 1.04127 to 1.01060, saving model to checkpoints_part3/epoch-40-accu-0.7249-loss-1.0106.hdf5\n",
      "Epoch 41/60\n",
      "158071/158071 [==============================] - 227s 1ms/step - loss: 1.0188 - accuracy: 0.7233\n",
      "Epoch 42/60\n",
      "158071/158071 [==============================] - 227s 1ms/step - loss: 1.0243 - accuracy: 0.7207\n",
      "Epoch 43/60\n",
      "158071/158071 [==============================] - 227s 1ms/step - loss: 1.0192 - accuracy: 0.7223\n",
      "Epoch 44/60\n",
      "158071/158071 [==============================] - 227s 1ms/step - loss: 1.0028 - accuracy: 0.7265\n",
      "Epoch 45/60\n",
      "158071/158071 [==============================] - 227s 1ms/step - loss: 1.0221 - accuracy: 0.7210\n",
      "Epoch 46/60\n",
      "158071/158071 [==============================] - 227s 1ms/step - loss: 1.0311 - accuracy: 0.7193\n",
      "Epoch 47/60\n",
      "158071/158071 [==============================] - 227s 1ms/step - loss: 1.0291 - accuracy: 0.7189\n",
      "Epoch 48/60\n",
      "158071/158071 [==============================] - 227s 1ms/step - loss: 1.0244 - accuracy: 0.7202\n",
      "Epoch 49/60\n",
      "158071/158071 [==============================] - 227s 1ms/step - loss: 1.0273 - accuracy: 0.7209\n",
      "Epoch 50/60\n",
      "158071/158071 [==============================] - 227s 1ms/step - loss: 1.0337 - accuracy: 0.7174\n",
      "\n",
      "Epoch 00050: loss did not improve from 1.01060\n",
      "Epoch 51/60\n",
      "158071/158071 [==============================] - 227s 1ms/step - loss: 1.0372 - accuracy: 0.7167\n",
      "Epoch 52/60\n",
      "158071/158071 [==============================] - 227s 1ms/step - loss: 1.0373 - accuracy: 0.7163\n",
      "Epoch 53/60\n",
      "158071/158071 [==============================] - 227s 1ms/step - loss: 1.0419 - accuracy: 0.7148\n",
      "Epoch 54/60\n",
      "158071/158071 [==============================] - 227s 1ms/step - loss: 1.0522 - accuracy: 0.7122\n",
      "Epoch 55/60\n",
      "158071/158071 [==============================] - 231s 1ms/step - loss: 1.0512 - accuracy: 0.7123\n",
      "Epoch 56/60\n",
      "158071/158071 [==============================] - 213s 1ms/step - loss: 1.0777 - accuracy: 0.7063\n",
      "Epoch 57/60\n",
      "158071/158071 [==============================] - 207s 1ms/step - loss: 1.0635 - accuracy: 0.7094\n",
      "Epoch 58/60\n",
      "158071/158071 [==============================] - 207s 1ms/step - loss: 1.0700 - accuracy: 0.7085\n",
      "Epoch 59/60\n",
      "158071/158071 [==============================] - 207s 1ms/step - loss: 1.0742 - accuracy: 0.7064\n",
      "Epoch 60/60\n",
      "158071/158071 [==============================] - 207s 1ms/step - loss: 1.0736 - accuracy: 0.7076\n",
      "\n",
      "Epoch 00060: loss did not improve from 1.01060\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "part3_root_folder = 'checkpoints_part3'\n",
    "checkpointer3 = ModelCheckpoint(\n",
    "        filepath=part3_root_folder+'/epoch-{epoch:02d}-accu-{accuracy:.4f}-loss-{loss:.4f}.hdf5',\n",
    "        monitor='loss',\n",
    "        verbose=1,\n",
    "        save_best_only=True, mode='auto', period=10)\n",
    "logfile3 = CSVLogger(part3_root_folder+'/train.log', append=False, separator=',')\n",
    "adam = optimizers.Adam(lr=0.005)\n",
    "model3.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
    "history3 = model3.fit(X,Y,\n",
    "        batch_size=128,\n",
    "        epochs=60,\n",
    "        verbose=1,\n",
    "        callbacks=[checkpointer3, logfile3],\n",
    "        workers=4)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Part 3: On epoch 40, the GRU + BTT model's cross-entropy loss on the train set is 1.0106.     "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "By comparing the other two models, the GRU + BTT model has the lowest loss and the highest accuracy on the train set. The loss order is GRU + BTT < SimpleRNN + BTT < SimpleRNN + TBTT. The accuracy order is GRU + BTT >  SimpleRNN + BTT > SimpleRNN + TBTT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " selected seed: we\n",
      "\n",
      "SimpleRNN + TBTT model predicted output: we aloud _unk_ aloud _unk_ aloud _unk_ aloud _unk_ aloud _unk_ aloud _unk_ aloud _unk_ aloud\n",
      "SimpleRNN + BTT model predicted output:  we have not yet been seen in any house nor can we lie distinguish by our\n",
      "GRU + BTT model predicted output:        we are undone lady we are undone to hear speak sir and since he play but\n",
      "\n",
      " selected seed: rather\n",
      "\n",
      "SimpleRNN + TBTT model predicted output: rather actor aloud _unk_ aloud _unk_ aloud _unk_ aloud _unk_ aloud _unk_ aloud _unk_ aloud _unk_\n",
      "SimpleRNN + BTT model predicted output:  rather say i play the _unk_ do do not be forgot right noble lord the good\n",
      "GRU + BTT model predicted output:        rather no no more shall fight with such gentle lambs and throw them hither in the\n",
      "\n",
      " selected seed: first\n",
      "\n",
      "SimpleRNN + TBTT model predicted output: first future _unk_ aloud _unk_ aloud _unk_ aloud _unk_ aloud _unk_ aloud _unk_ aloud _unk_ aloud\n",
      "SimpleRNN + BTT model predicted output:  first senator no more words we three are but thyself well so _unk_ and _unk_ _unk_\n",
      "GRU + BTT model predicted output:        first citizen ye good woman be he that seeks his part in thy day do you\n",
      "\n",
      " selected seed: what\n",
      "\n",
      "SimpleRNN + TBTT model predicted output: what nobler placed absence _unk_ aloud _unk_ aloud _unk_ aloud _unk_ aloud _unk_ aloud _unk_ aloud\n",
      "SimpleRNN + BTT model predicted output:  what is the wager first i would have _unk_ the people did note us to death\n",
      "GRU + BTT model predicted output:        what news friar of that end of it can not be but to a king what\n",
      "\n",
      " selected seed: set\n",
      "\n",
      "SimpleRNN + TBTT model predicted output: set wasp aid seest choice vassal _unk_ aloud _unk_ aloud _unk_ aloud _unk_ aloud _unk_ aloud\n",
      "SimpleRNN + BTT model predicted output:  set it down in every borough as we few words suffice and therefore if you say\n",
      "GRU + BTT model predicted output:        set her two courses off to sea again lay her off with our death but full\n",
      "\n",
      " selected seed: these\n",
      "\n",
      "SimpleRNN + TBTT model predicted output: these strengthen nobler placed absence _unk_ aloud _unk_ aloud _unk_ aloud _unk_ aloud _unk_ aloud _unk_\n",
      "SimpleRNN + BTT model predicted output:  these are news indeed i am sure of you look out sorrow drinks our heart to\n",
      "GRU + BTT model predicted output:        these that have been in the ear and a match and a and a and a\n",
      "\n",
      " selected seed: welcome\n",
      "\n",
      "SimpleRNN + TBTT model predicted output: welcome placed absence _unk_ aloud _unk_ aloud _unk_ aloud _unk_ aloud _unk_ aloud _unk_ aloud _unk_\n",
      "SimpleRNN + BTT model predicted output:  welcome harry what will not so resign one thing they play not thither let me _unk_\n",
      "GRU + BTT model predicted output:        welcome good cambio is all the spring to the earth but power still have i _unk_\n",
      "\n",
      " selected seed: each\n",
      "\n",
      "SimpleRNN + TBTT model predicted output: each hounds nought absence _unk_ aloud _unk_ aloud _unk_ aloud _unk_ aloud _unk_ aloud _unk_ aloud\n",
      "SimpleRNN + BTT model predicted output:  each word thou hast spoke with thee for thou art _unk_ to death her for his\n",
      "GRU + BTT model predicted output:        each word hath thine true and then for thee thine to murder thee then for thee\n",
      "\n",
      " selected seed: keep\n",
      "\n",
      "SimpleRNN + TBTT model predicted output: keep rites choice vassal _unk_ aloud _unk_ aloud _unk_ aloud _unk_ aloud _unk_ aloud _unk_ aloud\n",
      "SimpleRNN + BTT model predicted output:  keep thou the napkin and go boast of your _unk_ to her and leave his passage\n",
      "GRU + BTT model predicted output:        keep time how sour sweet grace have brought thy tears there none but therefore let be\n",
      "\n",
      " selected seed: whiles\n",
      "\n",
      "SimpleRNN + TBTT model predicted output: whiles aloud _unk_ aloud _unk_ aloud _unk_ aloud _unk_ aloud _unk_ aloud _unk_ aloud _unk_ aloud\n",
      "SimpleRNN + BTT model predicted output:  whiles lions war and battle for first he has as many a one as you are\n",
      "GRU + BTT model predicted output:        whiles we have struck for _unk_ and _unk_ _unk_ our brother battle have got the _unk_\n"
     ]
    }
   ],
   "source": [
    "# Predict\n",
    "def generate_seq_first(model_chosen, input_text, num_output):\n",
    "    model1.load_weights(model_chosen)\n",
    "    pred_sentence = input_text\n",
    "    for _ in range(num_output):\n",
    "#         print('input_text:',input_text)\n",
    "        encoded = word_dict[input_text]\n",
    "        pred_y = model1.predict([[encoded]], verbose=0)\n",
    "#         print('pred_y:', np.argmax(pred_y))\n",
    "        pred_word = idx2word[np.argmax(pred_y)] \n",
    "        pred_sentence += ' ' + pred_word\n",
    "        # set prediction to the input for the next iteration\n",
    "        input_text = pred_word\n",
    "    print('SimpleRNN + TBTT model predicted output:', pred_sentence.strip())\n",
    "    \n",
    "def generate_seq_second(model_chosen, input_text, num_output):\n",
    "    model2.load_weights(model_chosen)\n",
    "    for _ in range(num_output):\n",
    "        words = nltk.word_tokenize(input_text);\n",
    "        encoded = [word_dict.get(word, 1) for word in words]\n",
    "        input_x = pad_sequences([encoded], maxlen=max_length-1, padding='pre')\n",
    "        pred_y = model2.predict(input_x, verbose=0)\n",
    "        pred_word = idx2word[np.argmax(pred_y)] \n",
    "        input_text += ' ' + pred_word\n",
    "    print('SimpleRNN + BTT model predicted output: ', input_text.strip())\n",
    "\n",
    "def generate_seq_third(model_chosen, input_text, num_output):\n",
    "    model3.load_weights(model_chosen)\n",
    "    for _ in range(num_output):\n",
    "        words = nltk.word_tokenize(input_text);\n",
    "        encoded = [word_dict.get(word, 1) for word in words]\n",
    "        input_x = pad_sequences([encoded], maxlen=max_length-1, padding='pre')\n",
    "        pred_y = model3.predict(input_x, verbose=0)\n",
    "        pred_word = idx2word[np.argmax(pred_y)] \n",
    "        input_text += ' ' + pred_word\n",
    "    print('GRU + BTT model predicted output:       ', input_text.strip())\n",
    "\n",
    "num_output = 15\n",
    "model1_chosen = 'checkpoints_part1/best.hdf5'\n",
    "model2_chosen = 'checkpoints_part2/best.hdf5'\n",
    "model3_chosen = 'checkpoints_part3/best.hdf5'\n",
    "\n",
    "# Choose a random seed\n",
    "input_texts = ['we', 'rather', 'first', 'what', 'set', 'these', 'welcome', 'each', 'keep', 'whiles']\n",
    "for i in range(len(input_texts)):\n",
    "#     rand = random.randint(0,len(tokens)-1)\n",
    "#     input_text = tokens[rand]\n",
    "    input_text = input_texts[i]\n",
    "    print('\\n selected seed:', input_text + '\\n')\n",
    "    # SimpleRNN + TBTT\n",
    "    generate_seq_first(model1_chosen, input_text, num_output)\n",
    "    # SimpleRNN + BTT \n",
    "    generate_seq_second(model2_chosen, input_text, num_output)\n",
    "    # GRU + BTT\n",
    "    generate_seq_third(model3_chosen, input_text, num_output)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "The GRU + BTT model generates better sentence than simpleRNN + BTT model. The BTT model generates better sentences than TBTT model. The sentence generated by simpleRNN + BTT and GRU + BTT model look like proper English. For example \"we have not yet been seen in any house nor can we lie distinguish by our\", \" we are undone lady\", \"rather say i play the\", \"set it down\", \"no more than\", match train data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['mars', 'wednesday', 'attempt', 'baby', 'bank']\n",
      "['water', 'news', 'peace', 'mother', 'money']\n",
      "[2.94, 2.22, 4.25, 7.85, 8.12]\n"
     ]
    }
   ],
   "source": [
    "# Part4\n",
    "import gluonnlp as nlp\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "wordsim353 = nlp.data.WordSim353()\n",
    "sim_word1 = []\n",
    "sim_word2 = []\n",
    "scores = []\n",
    "for i in range(len(wordsim353)):\n",
    "    w1 = wordsim353[i][0].lower()\n",
    "    w2 = wordsim353[i][1].lower()\n",
    "    score = wordsim353[i][2]\n",
    "    if word_dict.get(w1) != None and word_dict.get(w2) != None:\n",
    "        sim_word1.append(w1)\n",
    "        sim_word2.append(w2)\n",
    "        scores.append(score)\n",
    "print(sim_word1[0:5])\n",
    "print(sim_word2[0:5])\n",
    "print(scores[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearman rank correlation on wordsim353 -0.136\n",
      "Spearman rank correlation on wordsim353 0.312\n",
      "Spearman rank correlation on wordsim353 0.349\n"
     ]
    }
   ],
   "source": [
    "embeddings1 = model1.layers[0].get_weights()[0]\n",
    "embeddings2 = model2.layers[0].get_weights()[0]\n",
    "embeddings3 = model3.layers[0].get_weights()[0]\n",
    "\n",
    "# Compare\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "def get_similarity_score(embeddings): \n",
    "    sim_values = []\n",
    "    for i in range(len(sim_word1)):\n",
    "        vec1 = embeddings[word_dict[sim_word1[i]]]\n",
    "        vec2 = embeddings[word_dict[sim_word2[i]]]\n",
    "        sim_val = cosine_similarity(vec1.reshape(1, -1), vec2.reshape(1, -1))[0][0]\n",
    "        sim_values.append(sim_val)\n",
    "    return sim_values\n",
    "\n",
    "model1_score = get_similarity_score(embeddings1)\n",
    "model2_score = get_similarity_score(embeddings2)\n",
    "model3_score = get_similarity_score(embeddings3)\n",
    "\n",
    "sr1 = stats.spearmanr(np.array(model1_score), np.array(scores))\n",
    "sr2 = stats.spearmanr(np.array(model2_score), np.array(scores))\n",
    "sr3 = stats.spearmanr(np.array(model3_score), np.array(scores))\n",
    "\n",
    "print('Spearman rank correlation on wordsim353 {}'.format(sr1.correlation.round(3)))\n",
    "print('Spearman rank correlation on wordsim353 {}'.format(sr2.correlation.round(3)))\n",
    "print('Spearman rank correlation on wordsim353 {}'.format(sr3.correlation.round(3)))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "To evaluate the extracted word representation for my trained RNN, I used wordsim353 data for similar word pairs. I first extracted word embeddings from each model. Then I computed cosine similarity scores. I also computed the Spearman Rank Correlation between the predicted similarity scores and the similarity scores from wordsim353 dataset.       \n",
    "The Spearman correlation coefficient value shows that GRU + BTT >  SimpleRNN + BTT > SimpleRNN + TBTT. GRU + BTT seems to have the best result.       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2983, 3980, 4755, 5740, 6680, 8642, 9552, 10546, 12480, 13108]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"This code is used to read all news and their labels\"\"\"\n",
    "import os\n",
    "import glob\n",
    "\n",
    "def to_categories(name, cat=[\"politics\",\"rec\",\"comp\",\"religion\"]):\n",
    "    for i in range(len(cat)):\n",
    "        if str.find(name,cat[i])>-1:\n",
    "            return(i)\n",
    "    print(\"Unexpected folder: \" + name) # print the folder name which does not include expected categories\n",
    "    return(\"wth\")\n",
    "\n",
    "lengths = [] # store length of each group\n",
    "\n",
    "def data_loader(images_dir):\n",
    "    categories = os.listdir(data_path)\n",
    "    news = [] # news content\n",
    "    groups = [] # category which it belong to\n",
    "    \n",
    "    for cat in categories:\n",
    "#         print(\"Category:\"+cat)\n",
    "        for the_new_path in glob.glob(data_path + '/' + cat + '/*'):\n",
    "            news.append(open(the_new_path,encoding = \"ISO-8859-1\", mode ='r').read())\n",
    "            groups.append(cat)\n",
    "    return news, list(map(to_categories, groups))\n",
    "\n",
    "data_path = \"20news_subsampled\"\n",
    "news, groups = data_loader(data_path)\n",
    "lengths = [i for i in range(1, len(groups)) if groups[i] != groups[i-1]]\n",
    "lengths.append(len(groups))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split each group to 90% train and 10% validataion\n",
    "news_train = []\n",
    "news_valid = []\n",
    "groups_train = []\n",
    "groups_valid = []\n",
    "for i in range(len(lengths)):\n",
    "    size = 0\n",
    "    if i == 0:\n",
    "        size = lengths[i]\n",
    "    else:\n",
    "        size = lengths[i] - lengths[i - 1] \n",
    "    train_size = int(0.9*size)\n",
    "    valid_size = size - train_size\n",
    "    if i == 0:\n",
    "        news_train += news[0:train_size]\n",
    "        news_valid += news[train_size : lengths[i]]\n",
    "        groups_train += groups[0:train_size]\n",
    "        groups_valid += groups[train_size : lengths[i]]\n",
    "    else:\n",
    "        news_train += news[lengths[i-1]:lengths[i-1] + train_size]\n",
    "        news_valid += news[lengths[i-1] + train_size : lengths[i]]\n",
    "        groups_train += groups[lengths[i-1]:lengths[i-1] + train_size]\n",
    "        groups_valid += groups[lengths[i-1] + train_size : lengths[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of train data tensor: (11793, 300)\n",
      "Shape of train label tensor: (11793, 4)\n",
      "Shape of validation data tensor: (1315, 300)\n",
      "Shape of validation label tensor: (1315, 4)\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer(20000)\n",
    "tokenizer.fit_on_texts(news)\n",
    "vocab_size = len(tokenizer.word_index) + 1 # add 0 as padding\n",
    "# print('vocab_size:', vocab_size)\\\n",
    "max_length = 200\n",
    "# avg = sum( map(len, sequences) ) / len(sequences) # average length is 292\n",
    "# train set\n",
    "sequences_train = tokenizer.texts_to_sequences(news_train)\n",
    "sequences_train = pad_sequences(sequences_train, maxlen=max_length, padding='pre')\n",
    "X_train = np.array(sequences_train)\n",
    "Y_train = to_categorical(np.asarray(groups_train))\n",
    "print('Shape of train data tensor:', X_train.shape)\n",
    "print('Shape of train label tensor:', Y_train.shape)\n",
    "# valid set\n",
    "sequences_valid = tokenizer.texts_to_sequences(news_valid)\n",
    "sequences_valid = pad_sequences(sequences_valid, maxlen=max_length, padding='pre')\n",
    "X_valid = np.array(sequences_valid)\n",
    "Y_valid = to_categorical(np.asarray(groups_valid))\n",
    "print('Shape of validation data tensor:', X_valid.shape)\n",
    "print('Shape of validation label tensor:', Y_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_11 (Embedding)     (None, 300, 50)           7408350   \n",
      "_________________________________________________________________\n",
      "simple_rnn_7 (SimpleRNN)     (None, 500)               275500    \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 128)               64128     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 4)                 516       \n",
      "=================================================================\n",
      "Total params: 7,748,494\n",
      "Trainable params: 7,748,494\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lpan/.local/lib/python3.5/site-packages/tensorflow_core/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11793 samples, validate on 1315 samples\n",
      "Epoch 1/30\n",
      "11793/11793 [==============================] - 59s 5ms/step - loss: 1.3401 - accuracy: 0.3567 - val_loss: 1.2982 - val_accuracy: 0.3726\n",
      "Epoch 2/30\n",
      "11793/11793 [==============================] - 54s 5ms/step - loss: 1.2521 - accuracy: 0.3774 - val_loss: 1.2223 - val_accuracy: 0.4403\n",
      "Epoch 3/30\n",
      "11793/11793 [==============================] - 58s 5ms/step - loss: 1.0841 - accuracy: 0.4974 - val_loss: 1.1357 - val_accuracy: 0.4882\n",
      "Epoch 4/30\n",
      "11793/11793 [==============================] - 56s 5ms/step - loss: 0.8612 - accuracy: 0.6233 - val_loss: 0.8988 - val_accuracy: 0.6266\n",
      "Epoch 5/30\n",
      "11793/11793 [==============================] - 55s 5ms/step - loss: 0.7195 - accuracy: 0.7037 - val_loss: 0.8562 - val_accuracy: 0.6715\n",
      "\n",
      "Epoch 00005: val_accuracy improved from -inf to 0.67148, saving model to checkpoints_part5/epoch-05-accu-0.6715.hdf5\n",
      "Epoch 6/30\n",
      "11793/11793 [==============================] - 55s 5ms/step - loss: 0.7897 - accuracy: 0.6763 - val_loss: 1.1345 - val_accuracy: 0.4654\n",
      "Epoch 7/30\n",
      "11793/11793 [==============================] - 55s 5ms/step - loss: 0.7709 - accuracy: 0.6631 - val_loss: 0.9645 - val_accuracy: 0.6897\n",
      "Epoch 8/30\n",
      "11793/11793 [==============================] - 55s 5ms/step - loss: 0.4752 - accuracy: 0.8205 - val_loss: 0.8759 - val_accuracy: 0.7217\n",
      "Epoch 9/30\n",
      "11793/11793 [==============================] - 55s 5ms/step - loss: 0.4220 - accuracy: 0.8383 - val_loss: 1.0461 - val_accuracy: 0.6433\n",
      "Epoch 10/30\n",
      "11793/11793 [==============================] - 55s 5ms/step - loss: 0.4036 - accuracy: 0.8546 - val_loss: 1.0179 - val_accuracy: 0.7529\n",
      "\n",
      "Epoch 00010: val_accuracy improved from 0.67148 to 0.75285, saving model to checkpoints_part5/epoch-10-accu-0.7529.hdf5\n",
      "Epoch 11/30\n",
      "11793/11793 [==============================] - 55s 5ms/step - loss: 0.2771 - accuracy: 0.9065 - val_loss: 1.0483 - val_accuracy: 0.7582\n",
      "Epoch 12/30\n",
      "11793/11793 [==============================] - 55s 5ms/step - loss: 0.2118 - accuracy: 0.9271 - val_loss: 1.0399 - val_accuracy: 0.7308\n",
      "Epoch 13/30\n",
      "11793/11793 [==============================] - 55s 5ms/step - loss: 0.2024 - accuracy: 0.9339 - val_loss: 0.9287 - val_accuracy: 0.7468\n",
      "Epoch 14/30\n",
      "11793/11793 [==============================] - 56s 5ms/step - loss: 0.1619 - accuracy: 0.9491 - val_loss: 1.0616 - val_accuracy: 0.7559\n",
      "Epoch 15/30\n",
      "11793/11793 [==============================] - 56s 5ms/step - loss: 0.1405 - accuracy: 0.9570 - val_loss: 1.1014 - val_accuracy: 0.7772\n",
      "\n",
      "Epoch 00015: val_accuracy improved from 0.75285 to 0.77719, saving model to checkpoints_part5/epoch-15-accu-0.7772.hdf5\n",
      "Epoch 16/30\n",
      "11793/11793 [==============================] - 56s 5ms/step - loss: 0.1513 - accuracy: 0.9536 - val_loss: 1.1353 - val_accuracy: 0.7757\n",
      "Epoch 17/30\n",
      "11793/11793 [==============================] - 56s 5ms/step - loss: 0.0986 - accuracy: 0.9694 - val_loss: 1.2324 - val_accuracy: 0.7970\n",
      "Epoch 18/30\n",
      "11793/11793 [==============================] - 56s 5ms/step - loss: 0.0969 - accuracy: 0.9708 - val_loss: 1.3072 - val_accuracy: 0.7437\n",
      "Epoch 19/30\n",
      "11793/11793 [==============================] - 56s 5ms/step - loss: 0.1001 - accuracy: 0.9699 - val_loss: 1.2498 - val_accuracy: 0.7894\n",
      "Epoch 20/30\n",
      "11793/11793 [==============================] - 56s 5ms/step - loss: 0.1010 - accuracy: 0.9687 - val_loss: 1.3760 - val_accuracy: 0.7894\n",
      "\n",
      "Epoch 00020: val_accuracy improved from 0.77719 to 0.78935, saving model to checkpoints_part5/epoch-20-accu-0.7894.hdf5\n",
      "Epoch 21/30\n",
      "11793/11793 [==============================] - 61s 5ms/step - loss: 0.0717 - accuracy: 0.9782 - val_loss: 1.3913 - val_accuracy: 0.7985\n",
      "Epoch 22/30\n",
      "11793/11793 [==============================] - 57s 5ms/step - loss: 0.0947 - accuracy: 0.9733 - val_loss: 1.8379 - val_accuracy: 0.5894\n",
      "Epoch 23/30\n",
      "11793/11793 [==============================] - 56s 5ms/step - loss: 0.1868 - accuracy: 0.9378 - val_loss: 1.3791 - val_accuracy: 0.7810\n",
      "Epoch 24/30\n",
      "11793/11793 [==============================] - 56s 5ms/step - loss: 0.0792 - accuracy: 0.9775 - val_loss: 1.6683 - val_accuracy: 0.7825\n",
      "Epoch 25/30\n",
      "11793/11793 [==============================] - 56s 5ms/step - loss: 0.1254 - accuracy: 0.9633 - val_loss: 1.3021 - val_accuracy: 0.7848\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.78935\n",
      "Epoch 26/30\n",
      "11793/11793 [==============================] - 56s 5ms/step - loss: 0.0709 - accuracy: 0.9785 - val_loss: 1.4999 - val_accuracy: 0.7856\n",
      "Epoch 27/30\n",
      "11793/11793 [==============================] - 56s 5ms/step - loss: 0.0848 - accuracy: 0.9747 - val_loss: 1.4505 - val_accuracy: 0.7475\n",
      "Epoch 28/30\n",
      "11793/11793 [==============================] - 56s 5ms/step - loss: 0.0622 - accuracy: 0.9813 - val_loss: 1.5917 - val_accuracy: 0.7863\n",
      "Epoch 29/30\n",
      "11793/11793 [==============================] - 56s 5ms/step - loss: 0.0522 - accuracy: 0.9826 - val_loss: 1.6715 - val_accuracy: 0.7688\n",
      "Epoch 30/30\n",
      "11793/11793 [==============================] - 56s 5ms/step - loss: 0.0510 - accuracy: 0.9828 - val_loss: 1.6820 - val_accuracy: 0.7810\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.78935\n"
     ]
    }
   ],
   "source": [
    "model5 = Sequential()\n",
    "model5.add(Embedding(vocab_size, 50, input_length=max_length, mask_zero=True))\n",
    "model5.add(SimpleRNN(500, activation='sigmoid'))\n",
    "model5.add(Dense(128, activation = 'relu'))\n",
    "model5.add(Dropout(0.5))\n",
    "model5.add(Dense(4, activation='softmax'))\n",
    "model5.summary()\n",
    "\n",
    "# Training\n",
    "part5_root_folder = 'checkpoints_part5'\n",
    "checkpointer5 = ModelCheckpoint(\n",
    "        filepath=part5_root_folder+'/epoch-{epoch:02d}-accu-{val_accuracy:.4f}.hdf5',\n",
    "        monitor='val_accuracy',\n",
    "        verbose=1,\n",
    "        save_best_only=True, mode='auto', period=5)\n",
    "logfile5 = CSVLogger(part5_root_folder+'/train.log', append=False, separator=',')\n",
    "model5.compile(loss='categorical_crossentropy', optimizer= 'adam', metrics=['accuracy'])\n",
    "history5 = model5.fit(X_train,Y_train,\n",
    "        batch_size=64,\n",
    "        epochs=30,\n",
    "        verbose=1,\n",
    "        callbacks=[checkpointer5, logfile5],\n",
    "        validation_data=(X_valid, Y_valid), \n",
    "        shuffle=True,\n",
    "        workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "My accuracy results on the validation set is 0.78935."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class: rec, Groud truth class:rec\n",
      "Predicted class: rec, Groud truth class:rec\n",
      "Predicted class: rec, Groud truth class:rec\n",
      "Predicted class: rec, Groud truth class:rec\n",
      "Predicted class: rec, Groud truth class:rec\n",
      "Predicted class: rec, Groud truth class:rec\n",
      "Predicted class: rec, Groud truth class:rec\n",
      "Predicted class: rec, Groud truth class:rec\n",
      "Predicted class: rec, Groud truth class:rec\n"
     ]
    }
   ],
   "source": [
    "def predict(model_chosen, start, end):\n",
    "    for k in range(start, end):\n",
    "        input_x = X_valid[k]\n",
    "        model5.load_weights(model_chosen)\n",
    "        pred = model5.predict(X_valid[0].reshape(1,300))\n",
    "        pred_class = cat[groups_valid[np.argmax(pred)]]\n",
    "        print('Predicted class: {0}, Groud truth class:{1}'.format(pred_class.strip(), cat[groups_valid[k]]))\n",
    "\n",
    "cat=[\"politics\",\"rec\",\"comp\",\"religion\"]\n",
    "model5_chosen = 'checkpoints_part5/epoch-15-accu-0.7772.hdf5'\n",
    "predict(model5_chosen, 1, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Backups\n",
    "# raw_text = raw_text.replace('\\n', ' ').replace('\\r', '') # replace new lines with spaces\n",
    "# sentences = nltk.sent_tokenize(raw_text)\n",
    "# max_length = 20 # truncate long sentence\n",
    "# sequences = list()\n",
    "# lengths = list()\n",
    "# for sentence in sentences:\n",
    "#     tokens = nltk.word_tokenize(sentence);\n",
    "#     encoded = [word_dict.get(word, 1) for word in tokens]\n",
    "#     lengths.append(min(len(encoded), max_length)-1)\n",
    "#     for i in range(1,min(len(encoded), max_length)):\n",
    "#         sequence = encoded[:i+1]\n",
    "#         sequences.append(sequence)\n",
    "# # max_length = max([len(seq) for seq in sequences])\n",
    "# sequences =  np.array(pad_sequences(sequences, maxlen=max_length, padding='pre'))\n",
    "# print(sequences.shape)\n",
    "# X = sequences[:,:-1] # length - 1\n",
    "# y = sequences[:,-1]\n",
    "# # print(X[0:5])\n",
    "# # print(y[0:5])\n",
    "# Y = to_categorical(y, num_classes=vocab_size)\n",
    "# print(X.shape)\n",
    "# print(Y.shape)\n",
    "\n",
    "# # def seq2sentence(seq):\n",
    "# #     sentence = ''\n",
    "# #     for i in range(len(seq)):\n",
    "# #         sentence += idx2word[seq[i]] + ' '\n",
    "# #     print(sentence.strip())\n",
    "# # seq2sentence([4308,   26, 2546, 4147, 3632]) \n",
    "\n",
    "# # Build model\n",
    "# model2 = Sequential()\n",
    "# model2.add(Embedding(vocab_size, 100, input_length=max_length-1, mask_zero=True))\n",
    "# model2.add(SimpleRNN(500, activation='sigmoid'))\n",
    "# model2.add(Dense(vocab_size, activation='softmax'))\n",
    "# model2.summary()\n",
    "\n",
    "# # Training\n",
    "# adam = optimizers.Adam(lr=0.005)\n",
    "# model2.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
    "\n",
    "# part2_root_folder = 'checkpoints_part2_batch'\n",
    "# def write_log(epoch, loss, accuracy):\n",
    "#     f = open(part2_root_folder+'/train.log', \"a\")\n",
    "#     f.write('epoch:{0:02d} loss: {1:.4f} accuracy: {2:.4f} \\n'.format(epoch + 1, loss, accuracy))\n",
    "    \n",
    "# epochs = 20\n",
    "# f = open(part2_root_folder+'/train.log', \"a\")\n",
    "# for epoch in range(epochs):\n",
    "#     start = 0\n",
    "#     for i in range(len(lengths)):\n",
    "#         length = lengths[i] # length of current sentence\n",
    "#         [loss, accuracy] = model2.train_on_batch(X[start: start+length], Y[start: start+length])\n",
    "#         start += length\n",
    "#     write_log(epoch, loss, accuracy)\n",
    "#     if((epoch + 1) % 5 == 0):\n",
    "#         model2.save(part2_root_folder+'/epoch-{0:02d}-accu-{1:.4f}-loss-{2:.4f}.hdf5'.format(epoch + 1, loss, accuracy))\n",
    "# f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
